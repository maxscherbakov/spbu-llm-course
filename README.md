# Enterprise RAG Challenge Solution

Это решение задачи по извлечению информации из финансовых годовых отчетов (Annual Reports) с использованием передовых методов RAG (Retrieval-Augmented Generation).

Система построена на базе гибридного парсинга, семантического разбиения текста и многоступенчатого поиска с использованием OpenAI API для генерации ответов.

## Особенности решения

### 1. Гибридный Парсинг
*   Используется **PyMuPDF** для быстрого извлечения текста.
*   Интегрирован **RapidOCR**. Система автоматически определяет страницы с таблицами-картинками (на основе площади изображений) и применяет OCR только к ним, сохраняя баланс между скоростью и качеством.
*   Надежное извлечение SHA1-хэша из имени файла.

### 2. Умная Индексация
*   **Semantic Chunking:** Использование `SemanticChunker` (LangChain Experimental) для разбиения текста по смысловым границам, а не просто по количеству символов.
*   **Embeddings:** Использование SOTA модели `BAAI/bge-m3` для создания векторных представлений.
*   **Vector DB:** Данные хранятся в `ChromaDB` для быстрого поиска.

### 3. Многоступенчатый Поиск
*   **Query Decomposition:** Сложные вопросы (сравнения, агрегация) автоматически разбиваются на под-вопросы с помощью LLM.
*   **Query Expansion:** Для каждого вопроса генерируются синонимичные поисковые запросы для повышения полноты (Recall).
*   **Global Reranking:** Найденные документы фильтруются и сортируются с помощью Cross-Encoder модели `BAAI/bge-reranker-v2-m3`.

### 4. Генерация
*   Модель: **GPT-4o-mini** (через OpenAI API).
*   Строгий промпт-инжиниринг для соблюдения типов данных (`number`, `boolean`, `names`).
*   Автоматическая валидация и форматирование ответов перед отправкой.

## Установка и запуск

### Предварительные требования
*   Python 3.10+
*   CUDA-совместимая видеокарта (рекомендуется 16GB VRAM для быстрой обработки, но будет работать и на CPU/T4).
*   API ключ OpenAI.

### Шаг 1. Клонирование и установка зависимостей

```bash
git clone https://github.com/maxscherbakov/spbu-llm-course.git
cd spbu-llm-course.git

# Создание виртуального окружения (рекомендуется)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Установка зависимостей
pip install -r requirements.txt
```

> **Важно:** Для работы OCR на видеокарте в `requirements.txt` указана ссылка на специальную версию `onnxruntime-gpu` для CUDA 12.

### Шаг 2. Настройка окружения

Создайте файл `.env` в корне проекта или экспортируйте переменную окружения с вашим ключом OpenAI:

```bash
# .env файл
OPENAI_API_KEY=sk-ваши_символы_здесь
```

### Шаг 3. Подготовка данных

Убедитесь, что структура папок выглядит так:
```
project/
├── data/
│   ├── pdfs/           # Папка с PDF файлами (0a61a....pdf)
│   └── questions.json  # Файл с вопросами
├── main.py
├── requirements.txt
└── .env
```

### Шаг 4. Запуск

```bash
python main.py
```

Скрипт автоматически:
1.  Выполнит парсинг и OCR (при первом запуске создаст кэш `raw_knowledge_base.pkl`).
2.  Создаст векторную базу данных `chroma_db`.
3.  Обработает все вопросы из `questions.json`.
4.  Сформирует файл `submission_Shcherbakov_v4.json`.
5.  Отправит результат на сервер проверки.

## Структура проекта

*   `main.py`: Основной скрипт, содержащий весь пайплайн.
*   `requirements.txt`: Список необходимых библиотек.
*   `data/`: Директория для входных данных.

---
**Автор:** Максим Щербаков, бакалавр, ИИиНоД, 3 курс

---
**Примечание:** Основная логика RAG-пайплайна и код разработаны мной самостоятельно в среде [Google Colab](https://colab.research.google.com/drive/14GLK9cndXTWLjKZRPmtieXdk-aqMHVPd?usp=sharing). Данный файл README был структурирован и оформлен с помощью LLM для более четкой подачи материала.